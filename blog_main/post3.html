
<!DOCTYPE HTML>
<html>

<meta http-equiv="content-type" content="text/html;charset=UTF-8" />
<head>
<title>CrazyLazyLife - Blog</title>
<link href="css/bootstrap.css" rel='stylesheet' type='text/css' />
<link href="css/style.css" rel='stylesheet' type='text/css' />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="keywords" content="face detection siamese network one shot learning trpliet loss function" />
<script type="application/x-javascript"> addEventListener("load", function() { setTimeout(hideURLbar, 0); }, false); function hideURLbar(){ window.scrollTo(0,1); } </script>
<link href='http://fonts.googleapis.com/css?family=Oswald:100,400,300,700' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Lato:100,300,400,700,900,300italic' rel='stylesheet' type='text/css'>
<script src="js/jquery.min.js"></script>
<script type="text/javascript" src="js/move-top.js"></script>
<script type="text/javascript" src="js/easing.js"></script>

<script type="text/javascript">
			jQuery(document).ready(function($) {
				$(".scroll").click(function(event){
					event.preventDefault();
					$('html,body').animate({scrollTop:$(this.hash).offset().top},900);
				});
			});
</script>

</head>
<body>
<script src='../../../../ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js'></script><script src="../../../../m.servedby-buysellads.com/monetization.js" type="text/javascript"></script>
<script>
(function(){
	if(typeof _bsa !== 'undefined' && _bsa) {
  		_bsa.init('flexbar', 'CKYI627U', 'placement:w3layoutscom');
  	}
})();
</script>
<script>
(function(){
if(typeof _bsa !== 'undefined' && _bsa) {
	_bsa.init('fancybar', 'CKYDL2JN', 'placement:demo');
}
})();
</script>
<script>
(function(){
	if(typeof _bsa !== 'undefined' && _bsa) {
  		_bsa.init('stickybox', 'CKYI653J', 'placement:w3layoutscom');
  	}
})();
</script>
<body>

<div class="header">
	 <div class="container">
		  <div class="logo">
			  <a href="blog_index.html"><img src="images/logo.jpg" title="" /></a>
		  </div>

			 <div class="top-menu">
				 <div class="search">
					 <form>
					 <input type="text" placeholder="" required="">
					 <input type="submit" value="">
					 </form>
				 </div>
				  <span class="menu"> </span>
				   <ul>
						<li class="active"><a href="blog_index.html">HOME</a></li>
						<li><a href="../index.html">MAIN</a></li>
						<div class="clearfix"> </div>
				 </ul>
			 </div>
			 <div class="clearfix"></div>
					<script>
					$("span.menu").click(function(){
					$(".top-menu ul").slideToggle("slow" , function(){
					});
					});
					</script>

	 </div>
</div>

<div class="single">
	 <div class="container">
		  <div class="col-md-8 single-main">
			  <div class="single-grid">
					<img src="https://images.newscientist.com/wp-content/uploads/2017/04/07104611/rexfeatures_5731006e.jpg" alt=""/>
		<div class="main_body">			<p>
						Hello Coders,
<br>
	The last post has been about the basic idea and the working of the <a href="">Convolutional Neural Network</a> architecture. This post will be on the various <strong>types of CNN</strong>, designed and implemented successfully in various fields of image processing and object recognition. Its important to have an idea of Convolutional Neural Network.
<br>
	{ Pictures like the assistant robot above, being used as feature image, might attract a lot of attention, even though it does not directly implies the idea of this post. ;) That's something I once read in an article. }
<br>
	You probably have heard of <a href="http://www.image-net.org/">ImageNet</a>. It is a large organized visual image database used by researchers and developers to train their models. Now, they host an annual competition named <a href="http://www.image-net.org/challenges/LSVRC/">ImageNet Large Scale Visual Recognition Challenge (ILSVRC)</a> – a competition related to object detection and image classification on a large scale. Generally, the top performers of this competition are able to set a benchmark in the field of object classification. This list of various architectures, unique in their designs, secured top position in this competition and are being successfully applied in various tasks.
<br>
	<strong>Note: Unless mentioned, these networks implement <em>same-padding</em>, which essentially preserves the original size of the image after convolution.</strong>
<br>
	Let’s have a look at them:
	<br>
	<span style="text-decoration: underline; font-size: 25px; color: black;">LeNet:</span><br>
	<img class=" size-full wp-image-1262 aligncenter" src="https://i0.wp.com/www.pyimagesearch.com/wp-content/uploads/2016/06/lenet_architecture.png" alt="lenet5" width="800" height="235" >
	No discussion of the CNN architectures can begin without this. A ground-breaking algorithm that was the first of its kind and capability, in-terms-of object classification, <strong>originally trained to classify hand written digits from 0 – 9, of the MNIST Dataset</strong>. It comprises of 7 – layers, all made of trainable parameters. It takes in a 32 X 32 pixel image, which was comparatively large in size w.r.t the images present in the data sets on which the network was trained. The activation function applied is <strong>RELU</strong> function. The layers are arranged in the following manner:
<br>
	<img class=" size-full wp-image-1272 aligncenter" src="https://note.abeffect.com/note/upload/12b16814c20d46488b6b096d43e9e0ee_image.png" alt="lenet_explain" width="850" height="291" >

		<br><span style="padding-left: 25px;">1. The <strong>First Convolutional Layer</strong> consist of <strong>6 filters</strong> of <strong>size 5 X 5</strong> and a <strong>stride of 1</strong>.</span>
		<br><span style="padding-left: 25px;">2. The <strong>Second Layer</strong> is a “<strong>sub-sampling</strong>” or <strong>average-pooling</strong> layer of <strong>size 2 X 2</strong> and a <strong>stride of 2</strong>.</span>
		<br><span style="padding-left: 25px;">3. The <strong>Third Layer</strong> is also a <strong>C</strong><strong>onvolutional layer</strong> consisting of <strong>16 filters of size 5 X 5 </strong>and<strong> stride of 1.</strong></span>
		<br><span style="padding-left: 25px;">4. The <strong>Fourth Layer</strong> is again an <strong>average-pooling layer</strong> of<strong> size 2 X 2 </strong>and<strong> stride of 2.</strong></span>
		<br><span style="padding-left: 25px;">5. The <strong>Fifth Layer</strong> is connecting the output of the <em>fourth layer</em> (<strong>400 parameters</strong>) to a <strong>fully connected layer </strong>of<strong> 120 nodes.</strong></span>
		<br><span style="padding-left: 25px;">6. The <strong>Sixth Layer</strong> is a similarly <strong>fully-connected layer consisting </strong>of<strong> 84 nodes</strong>, deriving from the outputs of the 120 nodes of the <em>fifth-layer.</em></span>
		<br><span style="padding-left: 25px;">7. The <strong>Seventh Layer (, or the last layer)</strong> consist of <strong>classifying the output of the last layer into 10 classes related to the 10-digits</strong> that it was primarily trained to classify.</span>
	<br>
	It was one of the successful digit-recognition algorithm of its time implemented to classify hand written digits. Present day implementation of this architecture, on the data sets, using various libraries, would earn you an <strong>accuracy of around 98.9 %.</strong>
<br>
	However, when it came to processing large size image and classifying among a large no of classes of object, this network failed to be effective in terms of computation cost or accuracy.
	<br><br><span style="text-decoration: underline; font-size: 25px; color: black;">AlexNet:</span><br>
	<img class=" size-full wp-image-1263 aligncenter" src="https://img.itw01.com/images/2018/03/27/21/5333_FpBBNq_V9JOME4.jpg!r1024x0.jpg" alt="alexnet" width="686" height="221" />
<br>
	<strong>AlexNet</strong> was the <strong>winner of the ImageNet ILSVRC-2012</strong> competition, was designed by the group consisting of <strong>Alex Krizhevsky, Ilya Sutskever and Geoffery E. Hinton</strong>. It was able to reduce the <strong>top-5 error rate to 15.3 %</strong> compared to the error rate of the runners-up of that competition which attained an error rate of 26.2%. The network is similar to the LeNet Architecture, but has a large no. of filters compared to the original LeNet, and thus was able to classify among a large class of objects. Moreover, it used “dropout” instead of regularization, to deal with overfitting. (Dropout essentially decreases the size of the no. of parameters to be accounted for). Let us define the layers in short.
<br>
	<img class="alignnone size-full wp-image-1271" src="https://www.spiedigitallibrary.org/ContentImages/Proceedings/9789/97890A/FigureImages/00267_97890A_Page_5_1.jpg" alt="alexnet_together" width="602" height="226" />
		<br>It takes in input a color <strong>(RGB)</strong> image of dimension <strong>227 X 227</strong>.

		<br><span style="padding-left: 25px;"> 1. First, a <strong>Convolution Layer (CL)</strong> of <strong>96 filters of size 11 X 11 and stride = 4.</strong></span>
		<br><span style="padding-left: 25px;"> 2. Next, a <strong>Max-Pooling Layer (M-PL)</strong> of <strong>filter size 3 X 3 and stride = 2.</strong></span>
		<br><span style="padding-left: 25px;"> 3. Again, a <strong>CL of 256 filters </strong>of<strong> size 5 X 5 and stride = 4.</strong></span>
		<br><span style="padding-left: 25px;"> 4. Then, a <strong>M-PL of filter size 3 X 3 and stride = 2.</strong></span>
		<br><span style="padding-left: 25px;"> 5. Again, a <strong>CL of 384 filters of size 3 X 3 and stride = 4.</strong></span>
		<br><span style="padding-left: 25px;"> 6. Again, a <strong>CL of 384 filters of size 3 X 3 and stride = 4.</strong></span>
		<br><span style="padding-left: 25px;"> 7. Again, a <strong>CL of 256 filters of size 3 X 3 and stride = 4.</strong></span>
		<br><span style="padding-left: 25px;"> 8. Then, a <strong>M-Pl of filter size 3 X 3 and stride = 2.</strong></span>
		<br><span style="padding-left: 25px;"> 9. The output of the last layer, when converted into input-layer like for the Fully Connected Block consists of 9261 nodes, <strong><em>fully connected</em> to a hidden layer with 4096 nodes.</strong></span>
		<br><span style="padding-left: 25px;">10. The first hidden layer is again <strong><em>fully connected</em> to another hidden layer consisting 4096 nodes.</strong></span>
		<br><span style="padding-left: 25px;">11. This last hidden layer is <strong><em>fully connected</em> to the output layer implementing “softmax regression” of 1000 nodes.</strong></span>
<br>	Now, all I have written might seem quite different from the architecture shown in the <em>first image (the original one)</em>. Take a closer look, for both two pipelines (or, two parts), <strong>add</strong> their no of channels in each block-output, and see that it matches with the description. The reason for this difference is that AlexNet was trained simultaneously on <strong>two Nvidia GeForce GTX 580 GPUs</strong>, which resulted in these two pipelines of the architecture.
<br>
	This network has <strong>62.3 million parameters</strong> and requires <strong>billions of computation units</strong>. This huge computation cost led to training of the architecture simultaneously on multiple GPUs to speed the process. The original network was trained on only two GPUs.
<br>
	<strong>One interesting result</strong> that they obtained from the network was after analyzing the filters of the first convolutional block from both the GPUs. They found that, while one generates high frequency gray-scale features, the other generated low-frequency color features.
<br>
	<img class="alignnone size-full wp-image-1264" src="https://docsplayer.org/docs-images/64/51694912/images/62-1.jpg" alt="feature_map_gpus" width="580" height="244" />
	<br><span style="text-decoration: underline;  font-size: 25px; color: black;">VGGNet 16:</span><br>
	This particular network architecture was the <strong>runners up </strong>of the<strong> ILSVRC-2014</strong> competition, designed by <strong>Simonyan and Zisserman</strong>. It was ale to achieve a <strong>top-5 error rate of 5.1%</strong>. Though it might look complicated with a whole bunch of parameters to be taken care of, it is actually very simple. Developers prefer it highly, when it comes to feature extraction because of the simple pattern that it follows. The basic <em>hyperparameters</em> regarding the filter size and the strides for both of the convolution layer and the pooling layer are constant: <strong>CONVOLUTION LAYER</strong> has <strong>filters of size 3 X 3</strong> and <strong>stride = 1</strong> and the <strong>MAX-POOLING LAYER</strong> has <strong>filters of size 2 X 2</strong> and <strong>stride = 2</strong>. These layers are applied in a particular order throughout the network. Only the no of filters defined for each <em>convolution block</em> differs. Let’s take a look:
<br>
	<img class="aligncenter size-full wp-image-1265" src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS1hR-Iw8gBi6dY3T2WTmhYLhmntE4D9IK-4qbQDYYxFIbUht1S" alt="vggnet" width="800" height="122" />
<br><br>
		It takes in a color (RGB) image of 224 X 224 dimensions.

		<br><span style="padding-left: 25px;"> 1. <strong>Convolutional Layer (CL) of 64 filters.</strong></span>
		<br><span style="padding-left: 25px;"> 2. <strong>CL of 64 filters again.</strong></span>
		<br><span style="padding-left: 25px;"> 3. <strong>Max-Pooling Layer (M-PL)</strong></span>
		<br><span style="padding-left: 25px;"> 4. <strong>CL of 128 filters.</strong></span>
		<br><span style="padding-left: 25px;"> 5. <strong>CL of 128 filters again.</strong></span>
		<br><span style="padding-left: 25px;"> 6. <strong>M-PL.</strong></span>
		<br><span style="padding-left: 25px;"> 7. <strong>CL of 256 filters.</strong></span>
		<br><span style="padding-left: 25px;"> 8. <strong>CL of 256 filters again.</strong></span>
		<br><span style="padding-left: 25px;"> 9. <strong>CL of 256 filters again.</strong></span>
		<br><span style="padding-left: 25px;">10. <strong>M-PL.</strong></span>
		<br><span style="padding-left: 25px;">11. <strong>CL of 512 filters.</strong></span>
		<br><span style="padding-left: 25px;">12. <strong>CL of 512 filters again.</strong></span>
		<br><span style="padding-left: 25px;">13. <strong>CL of 512 filters again.</strong></span>
		<br><span style="padding-left: 25px;">14. <strong>M-PL.</strong></span>
		<br><span style="padding-left: 25px;">15. <strong>CL of 512 filters.</strong></span>
		<br><span style="padding-left: 25px;">16. <strong>CL of 512 filters again.</strong></span>
		<br><span style="padding-left: 25px;">17. <strong>CL of 512 filters again.</strong></span>
		<br><span style="padding-left: 25px;">18. <strong>M-PL.</strong></span>
		<br><span style="padding-left: 25px;">19. The output of the last Pooling Layer is fed into a <strong><em>fully connected </em>hidden layer consisting of 4096 nodes.</strong></span>
		<br><span style="padding-left: 25px;">20. This is <strong>again <em>fully connected</em> to another hidden layer consisting again of 4096 nodes.</strong></span>
		<br><span style="padding-left: 25px;">21. This is <em>f<strong>ully connected</strong></em><strong> to an output layer implementing “softmax regression”, classifying among 1000 classes of objects.</strong></span>

	<br>
	That was a lot of layers. It thus has nearly <strong>140 millions parameters</strong> to handle, which makes the task, of implementing this network, challenging. However, weights of pre-trained VGGNet are easily available, and can be used by developers in their project.
	<br><span style="text-decoration: underline; font-size: 25px; color: black;">GooLeNet:</span><br>
	<img class="  wp-image-1268 aligncenter" src="http://www.csc.kth.se/~roelof/deepdream/googlenet2.png" alt="inception" width="715" height="324" />
<br>
	The <strong>GooLeNet or the Inception Network</strong> was the <strong>winner of the ILSVRC 2014</strong> competition, achieving a <strong>top-5 error rate of 6.67%</strong>, which was nearly equal to human level performance. The model was developed by Google and includes a smarter implementation of the original LeNet architecture. This is based on the idea of inception module.
<br>
	The basic idea behind the modules is that, instead of implementing convolutional layers of various hyperparameters in different layers, we do all the convolution together to output a result containing matrices from all the filter operations together. This is an image of a simple inception module with various convolutional layer implemented together:
<br>
	<img class=" size-full wp-image-1269 aligncenter" src="https://joelouismarino.github.io/images/blog_images/blog_googlenet_keras/inception_module.png" alt="inception_module" width="253" height="160" />
<br>
	The concatenated output consists results from all the convolution operation. Notice that one layer of convolution containing filters of size 1 X 1 is implemented. This reduced the size of the image on which a further convolutional layer, containing filters of size 5 X 5, is applied. The reason behind this is that, the <strong>total no. of computation units is reduced</strong> to a large extent.
<br>
	For example, when a <strong>Conv. Layer of  32 filter size 5 X 5</strong> is applied on some-layer <strong>output matrices of dimension say 28 X 28 X 192</strong>. Thus the total no of computations are <strong>28 X 28 X 32 (the output matrices size) *  5 X 5 X 192 (the size of the weights matrices)</strong> <strong>= 120 million (nearly)</strong>.
<br>
	While if a <strong>Conv. Layer of 16 filters of size 1 X 1</strong> is applied first, before the implementation of the Conv. Layer of 32 filters of size 5 X 5, the <strong>size of the matrices</strong> decreases to <strong>28 X 28 X 16</strong> and then the second convolution is done.
<br>
	Thus the total no of computations = { <strong>28 X 28 X 16(output of first conv layer) * 1 X 1 X 192 (size of the weight matrices of the first conv layer)</strong> } + { <strong>28 X 28 X 32 (output of the second conv layer) * 5 X 5 X 16 (size of the weight matrices of the second conv layer) </strong>}
<br>
	= <strong>2.4 million + 10.0 million (nearly)</strong>
<br>
	= <strong>12.4 million (nearly)</strong>
<br>
	, which is significantly less than the 120 million weights. Thus, over all the total cost decreases.
<br>
	The inception module shown above (the image is difficult to view, but believe me, I found no better image that might have clearer details), is sort of the <strong>building blocks</strong> of this network. Take a close look at the inception network image. It is a stack of a lot of ‘<em>inception blocks</em>’ with some Max-Pooling Layers in between some blocks to alter the dimension of the image. The <strong>last layers are <em>fully connected</em> network layers</strong> followed by <strong>“softmax regression” for classification in the output layer</strong>.
<br><span style="text-decoration: underline; font-size: 25px; color: black;">ResNets:</span><br>
	<img class="alignnone size-full wp-image-1266" src="https://tse4.mm.bing.net/th?id=OIP.VWCKvNUQ-lxZYoPOFn-S7AHaCG" alt="resnet" width="800" height="226" />
<br>
	Probably after AlexNet, the most ground-breaking development in the field of CNN architecture development happened with<strong> ResNet or Residual Networks</strong>. This is based on the<strong> idea of “<em>skip-connections</em>”</strong> and implements <strong>heavy batch-normalization</strong>, that help it in training over thousands of layers effectively, without degrading the performance in the long run.
<br>
	The problem rose with the training of deeper networks. The problem of <strong>“vanishing gradient”</strong> where repeated multiplication being done, as the gradient is being back-propagated, makes tha gradient infinitively small. This results in degradation of performance. (Take a look at back-propagation and gradient descent for having a clear knowledge of what actually happens at the training phase.)
<br>
	The idea that was infused in this architecture was “<em>identity shortcut connection</em>” that implies transferring the results of a few layers to some deeper layers skipping some of the other layers in between. This image might help you to understand the idea:
<br>
	<img class=" size-full wp-image-1267 aligncenter" src="https://images2018.cnblogs.com/blog/1182370/201808/1182370-20180824105739205-208271038.png" alt="skip_connection_image" width="520" height="270" />
<br>
	<strong>The intuition behind it, was that the deeper layers should not produce higher training errors than its shallower counterparts. The skip-connections were done to implement this idea. The developers of this network implemented a pre-activation variant of the residual block, in which gradients can flow through the shortcut connection to the earlier layers, thus reducing the “vanishing gradient” problem.</strong>
<br>
	Hopefully the image is able to explain itself. This <strong>1001 layer deep ResNet</strong> achieved a <strong>top-5 error rate of 3.57%</strong>, which actually beats human – level performance on the dataset. Despite it deep network, it delivered better performance than most VGGNet architecture. It <strong>bagged all the awards of the ILSVRC 2015 over the fields of classification, detection and localization</strong>.
<br>
	Hope you enjoyed reading it. Please comment, if there is any mistake or misinformation provided from my side. Any form of suggestion is welcome.
<br>
	Live long and Code
</div>

			 <ul class="comment-list">
		  		   <h5 class="post-author_head">Written by <a href="#" title="Posts by admin" rel="author">@crazylazylife</a></h5>
		  		   <li><img src="images/avatar.png" class="img-responsive" alt="">
		  		   <div class="desc">
		  		   <p>View all posts by: <a href="#" title="Posts by admin" rel="author">crazylazylife</a></p>
		  		   </div>
		  		   <div class="clearfix"></div>
		  		   </li>
		  	  </ul>
			  <div class="content-form">
					 <h3>Leave a comment</h3>
					<form>
						<input type="text" placeholder="Name" required/>
						<input type="text" placeholder="Email" required/>
						<input type="text" placeholder="Phone" required/>
						<textarea placeholder="Message"></textarea>
						<input type="submit" value="SEND"/>
				   </form>
						 </div>
		  </div>
			  <div class="clearfix"></div>
		  </div>
	  </div>


<div class="footer">
	<div class="container">
		<p>CRAZYLAZYLIFE Personal Blog . All rights reserved </p>
	</div>
</div>
